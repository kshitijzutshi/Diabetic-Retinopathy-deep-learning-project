{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"vgg16 training code.ipynb","provenance":[],"authorship_tag":"ABX9TyN7dSWHMMsVrHzKeuZ+kCbp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"wtvEcLtAIpWG"},"source":["Code for training the VGG 16 network using Keras with Tensorflow Backend:"]},{"cell_type":"code","metadata":{"id":"EUZQUVLUIqt-"},"source":["import numpy as np\n","import os\n","import time\n","from vgg16 import VGG16\n","from keras.preprocessing import image\n","from imagenet_utils import preprocess_input, decode_predictions\n","from keras.layers import Dense, Activation, Flatten\n","from keras.layers import merge, Input\n","from keras.models import Model\n","from keras.utils import np_utils\n","from sklearn.utils import shuffle\n","from sklearn.cross_validation import train_test_split\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oBkjpzk3Itov"},"source":["# Loading the training data\n","PATH = '/mount'\n","# Define data path\n","data_path = PATH \n","data_dir_list = os.listdir(data_path)\n","img_data_list=[]\n","y=0;\n","for dataset in data_dir_list:\n","\timg_list=os.listdir(data_path+'/'+ dataset)\n","\tprint ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n","\tfor img in img_list:\n","\t\timg_path = data_path + '/'+ dataset + '/'+ img \n","\t\timg = image.load_img(img_path, target_size=(224, 224))\n","\t\tx = image.img_to_array(img)\n","\t\tx = np.expand_dims(x, axis=0)\n","\t\tx = preprocess_input(x)\n","\t\tx = x/255\n","\n","\t\ty=y+1\n","\t\tprint('Input image shape:', x.shape)\n","\t\tprint(y)\n","\t\timg_data_list.append(x)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DBGmmqjAIwum"},"source":["img_data = np.array(img_data_list)\n","#img_data = img_data.astype('float32')\n","print (img_data.shape)\n","img_data=np.rollaxis(img_data,1,0)\n","print (img_data.shape)\n","img_data=img_data[0]\n","print (img_data.shape)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v2_vC89uIzFF"},"source":["# Define the number of classes\n","num_classes = 2\n","num_of_samples = img_data.shape[0]\n","labels = np.ones((num_of_samples,),dtype='int64')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ci1nMZDI2RX"},"source":["labels[0:3001]=0\n","labels[3001:]=1\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TCd6n49NI29W"},"source":["names = ['YES','NO']\n","\t  \n","# convert class labels to on-hot encoding\n","Y = np_utils.to_categorical(labels, num_classes)\n","\n","#Shuffle the dataset\n","x,y = shuffle(img_data,Y, random_state=2)\n","# Split the dataset\n","X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n","\n","image_input = Input(shape=(224, 224, 3))\n","\n","model = VGG16(input_tensor=image_input, include_top=True,weights='imagenet')\n","\n","model.summary()\n","\n","last_layer = model.get_layer('block5_pool').output\n","x= Flatten(name='flatten')(last_layer)\n","x = Dense(128, activation='relu', name='fc1')(x)\n","x = Dense(128, activation='relu', name='fc2')(x)\n","out = Dense(num_classes, activation='softmax', name='output')(x)\n","custom_vgg_model2 = Model(image_input, out)\n","custom_vgg_model2.summary()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o1RT8NC7I6QW"},"source":[""],"execution_count":null,"outputs":[]}]}